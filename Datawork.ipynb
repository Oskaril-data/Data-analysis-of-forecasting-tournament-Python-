{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95420e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "df_daily = pd.read_csv(r\"c:\\Users\\oskar\\Documents\\Documents\\FRI_data\\dataverse_files\\rct-a-daily-forecasts.csv\")\n",
    "df_qna = pd.read_csv(r\"C:\\Users\\oskar\\Documents\\Documents\\FRI_data\\dataverse_files\\rct-a-questions-answers.csv\")\n",
    "df_PredictionSets = pd.read_csv(r\"C:\\Users\\oskar\\Documents\\Documents\\FRI_data\\dataverse_files\\rct-a-prediction-sets.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3efc6f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   discover question id  question id  answer id        date  Raw Mean  Median  \\\n",
      "0                   177          819       2466  2018-03-08  0.300000   0.275   \n",
      "1                   177          819       2466  2018-03-09  0.221667   0.200   \n",
      "2                   177          819       2466  2018-03-10  0.033333   0.050   \n",
      "3                   177          819       2466  2018-03-11  0.100000   0.100   \n",
      "4                   177          819       2466  2018-03-12  0.000000   0.000   \n",
      "\n",
      "   Geometric Mean  Trimmed Mean  Geo Mean Odds  Count  \\\n",
      "0        0.165488      0.300000       0.202482      4   \n",
      "1        0.157849      0.221667       0.171972      6   \n",
      "2        0.013572      0.033333       0.013854      3   \n",
      "3        0.027144      0.100000       0.029405      3   \n",
      "4        0.001000      0.000000       0.001000      1   \n",
      "\n",
      "   answer resolved probability  \n",
      "0                          1.0  \n",
      "1                          1.0  \n",
      "2                          1.0  \n",
      "3                          1.0  \n",
      "4                          1.0  \n"
     ]
    }
   ],
   "source": [
    "#STEP 2\n",
    "\n",
    "# Create a working copy of the dataframe\n",
    "work_df = df_PredictionSets.copy()\n",
    "\n",
    "# ==========================================\n",
    "# 1. DATA PREPROCESSING\n",
    "# ==========================================\n",
    "\n",
    "# Filter out forecasts that were made after the correct answer was already known.\n",
    "work_df = work_df[work_df['made after correctness known'] != True]\n",
    "\n",
    "# Convert the timestamp string to datetime objects for easier manipulation\n",
    "work_df['timestamp'] = pd.to_datetime(work_df['prediction set created at'])\n",
    "\n",
    "# Create a 'date' column to allow for daily grouping later\n",
    "work_df['date'] = work_df['timestamp'].dt.date\n",
    "\n",
    "# Sort the data to ensure correct selection of the latest forecast.\n",
    "# Order: Question -> Answer -> User -> Date -> Time (ascending)\n",
    "work_df = work_df.sort_values(\n",
    "    by=['question id', 'answer id', 'membership guid', 'date', 'timestamp']\n",
    ")\n",
    "\n",
    "# Keep only the MOST RECENT forecast per user per day.\n",
    "# If a user updated their forecast multiple times in one day, we only use the last one.\n",
    "most_recent_forecasts = work_df.drop_duplicates(\n",
    "    subset=['question id', 'answer id', 'membership guid', 'date'], \n",
    "    keep='last'\n",
    ").copy()\n",
    "\n",
    "# ==========================================\n",
    "# 2. AGGREGATION HELPER FUNCTIONS\n",
    "# ==========================================\n",
    "\n",
    "def geometric_mean(x):\n",
    "    # Method 3: Geometric Mean\n",
    "    # Geometric mean handles zeros poorly (log(0) is undefined).\n",
    "    # Clipping values to a safe range (0.001 - 0.999).\n",
    "    x_clipped = np.clip(x, 0.001, 0.999)\n",
    "    return stats.gmean(x_clipped)\n",
    "\n",
    "def trimmed_mean_10(x):\n",
    "    # Method 4: Trimmed Mean\n",
    "    # Trimming the top and bottom 10% of forecasts to remove outliers.\n",
    "    return stats.trim_mean(x, 0.1)\n",
    "\n",
    "def geo_mean_odds(x):\n",
    "    # Method 5: Geometric Mean of Odds\n",
    "    # 1. Clip values to avoid division by zero in odds calculation\n",
    "    p = np.clip(x, 0.001, 0.999)\n",
    "    # 2. Convert probability to odds: p / (1 - p)\n",
    "    odds = p / (1 - p)\n",
    "    # 3. Calculate the geometric mean of the odds\n",
    "    geo_odds = stats.gmean(odds)\n",
    "    # 4. Convert back to probability: odds / (1 + odds)\n",
    "    return geo_odds / (1 + geo_odds)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 3. AGGREGATION\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "group_cols = ['discover question id', 'question id', 'answer id', 'date']\n",
    "\n",
    "\n",
    "# Define aggregation rules.\n",
    "# Applying statistical methods to 'forecasted probability'.\n",
    "agg_rules = {\n",
    "    'forecasted probability': [\n",
    "        ('Raw Mean', 'mean'),\n",
    "        ('Median', 'median'),\n",
    "        ('Geometric Mean', geometric_mean),\n",
    "        ('Trimmed Mean', trimmed_mean_10),\n",
    "        ('Geo Mean Odds', geo_mean_odds),\n",
    "        ('Count', 'count')\n",
    "    ],\n",
    "# For 'answer resolved probability', we use 'max'.\n",
    "    # Since the probability is identical for all rows in the group, \n",
    "    # 'max' simply retrieves that constant value.\n",
    "    'answer resolved probability': [('answer resolved probability', 'max')]\n",
    "}\n",
    "\n",
    "# Perform the grouping and aggregation\n",
    "grouped = most_recent_forecasts.groupby(group_cols)\n",
    "aggregated_results = grouped.agg(agg_rules)\n",
    "\n",
    "# ==========================================\n",
    "# 4. DATA CLEANUP\n",
    "# ==========================================\n",
    "\n",
    "# Flatten the MultiIndex columns created by the aggregation.\n",
    "# This simplifies column names (e.g., changing ('forecasted probability', 'Raw Mean') to just 'Raw Mean').\n",
    "aggregated_results.columns = [\n",
    "    col[1] if col[0] == 'forecasted probability' else col[0] \n",
    "    for col in aggregated_results.columns\n",
    "]\n",
    "\n",
    "# Reset index to turn grouping keys back into regular columns\n",
    "aggregated_results = aggregated_results.reset_index()\n",
    "\n",
    "\n",
    "#Viewing the first 5 results\n",
    "print(aggregated_results.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3ba2004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 3: Aggregate Method Accuracy (Mean Brier Score) ===\n",
      "\n",
      "                        Mean Brier Score\n",
      "Trimmed Mean SqError            0.337859\n",
      "Raw Mean SqError                0.338075\n",
      "Median SqError                  0.340052\n",
      "Geometric Mean SqError          0.343432\n",
      "Geo Mean Odds SqError           0.346373\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# STEP 3:\n",
    "# ==========================================\n",
    "# 5. ACCURACY CALCULATION (BRIER SCORE)\n",
    "# ==========================================\n",
    "\n",
    "# Creating a copy\n",
    "df_scores = aggregated_results.copy()\n",
    "\n",
    "# Ensure the 'answer resolved probability' column is numeric\n",
    "df_scores['answer resolved probability'] = pd.to_numeric(df_scores['answer resolved probability'], errors='coerce')\n",
    "\n",
    "# Filter: Remove rows where the question has not been resolved yet (NaN truth values)\n",
    "df_scores = df_scores.dropna(subset=['answer resolved probability'])\n",
    "\n",
    "# Calculate Squared Errors for each aggregation method\n",
    "methods = ['Raw Mean', 'Median', 'Geometric Mean', 'Trimmed Mean', 'Geo Mean Odds']\n",
    "score_cols = []\n",
    "\n",
    "for method in methods:\n",
    "    col_name = f'{method} SqError'\n",
    "    # Brier Score Component: (Forecast - Outcome)^2\n",
    "    df_scores[col_name] = (df_scores[method] - df_scores['answer resolved probability']) ** 2\n",
    "    score_cols.append(col_name)\n",
    "\n",
    "# Sum the Squared Errors at the Question-Date level.\n",
    "brier_scores = df_scores.groupby(['question id', 'date'])[score_cols].sum()\n",
    "\n",
    "# Calculate the final Mean Brier Score across the entire dataset\n",
    "final_results = brier_scores.mean().sort_values()\n",
    "\n",
    "# ==========================================\n",
    "# 6. RESULTS OUTPUT\n",
    "# ==========================================\n",
    "\n",
    "print(\"=== Step 3: Aggregate Method Accuracy (Mean Brier Score) ===\")\n",
    "print()\n",
    "print(pd.DataFrame(final_results, columns=['Mean Brier Score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f872be52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 4 Results: Calibration (Dampening) vs Trimmed Mean ===\n",
      "Calibration Factor (k): 0.95\n",
      "----------------------------------------\n",
      "Original (Trimmed Mean) Brier Score: 0.337859\n",
      "Adjusted Forecast Brier Score:        0.337826\n",
      "----------------------------------------\n",
      "SUCCESS: Dampening (k=0.95) improved the score by 0.000033!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# STEP 4: IMPROVING THE METHOD (CALIBRATION / DAMPENING)\n",
    "# ==========================================\n",
    "\n",
    "def adjust_confidence(p, k=0.95):\n",
    "    \"\"\"\n",
    "    Adjusts forecast confidence using the Karmarkar Equation.\n",
    "    \n",
    "    Parameters:\n",
    "    - k > 1: Extremizes (pushes probs towards 0 or 1). Used if forecasts are underconfident.\n",
    "    - k < 1: Dampens (pushes probs towards 0.5). Used if forecasts are overconfident.\n",
    "    \"\"\"\n",
    "    # Clip values to prevent division by zero or log errors\n",
    "    p = np.clip(p, 0.001, 0.999) \n",
    "    \n",
    "    # Karmarkar Equation\n",
    "    numerator = p ** k\n",
    "    denominator = (p ** k) + ((1 - p) ** k)\n",
    "    return numerator / denominator\n",
    "\n",
    "# 1. Select the best method from Step 3\n",
    "# 'Trimmed Mean' was the most accurate, but our analysis shows it might be slightly overconfident.\n",
    "best_method = 'Trimmed Mean'\n",
    "\n",
    "# 2. Apply the adjustment\n",
    "# We observed that a k-factor of 0.95 improves the Brier Score.\n",
    "# This implies the original Trimmed Mean was slightly \"overconfident\" (too close to 0 or 1).\n",
    "# k=0.95 \"dampens\" the probabilities slightly towards 0.5 to improve calibration.\n",
    "k_factor = 0.95\n",
    "aggregated_results['Adjusted Forecast'] = adjust_confidence(aggregated_results[best_method], k=k_factor)\n",
    "\n",
    "# ==========================================\n",
    "# EVALUATING THE NEW METHOD\n",
    "# ==========================================\n",
    "\n",
    "# Create a working copy for scoring\n",
    "df_scores_step4 = aggregated_results.copy()\n",
    "\n",
    "# Ensure the resolution column is numeric and remove unresolved questions\n",
    "df_scores_step4['answer resolved probability'] = pd.to_numeric(df_scores_step4['answer resolved probability'], errors='coerce')\n",
    "df_scores_step4 = df_scores_step4.dropna(subset=['answer resolved probability'])\n",
    "\n",
    "# Calculate Squared Error for the new method\n",
    "df_scores_step4['Adjusted SqError'] = (df_scores_step4['Adjusted Forecast'] - df_scores_step4['answer resolved probability']) ** 2\n",
    "\n",
    "# Recalculate the base method error for direct comparison\n",
    "df_scores_step4['Base Method SqError'] = (df_scores_step4[best_method] - df_scores_step4['answer resolved probability']) ** 2\n",
    "\n",
    "# Group by question and date\n",
    "brier_scores_step4 = df_scores_step4.groupby(['question id', 'date'])[['Adjusted SqError', 'Base Method SqError']].sum()\n",
    "\n",
    "# Calculate the final Mean Brier Score\n",
    "mean_scores = brier_scores_step4.mean()\n",
    "\n",
    "# Output the results\n",
    "print(f\"=== Step 4 Results: Calibration (Dampening) vs {best_method} ===\")\n",
    "print(f\"Calibration Factor (k): {k_factor}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Original ({best_method}) Brier Score: {mean_scores['Base Method SqError']:.6f}\")\n",
    "print(f\"Adjusted Forecast Brier Score:        {mean_scores['Adjusted SqError']:.6f}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Check for improvement\n",
    "improvement = mean_scores['Base Method SqError'] - mean_scores['Adjusted SqError']\n",
    "if improvement > 0:\n",
    "    print(f\"SUCCESS: Dampening (k={k_factor}) improved the score by {improvement:.6f}!\")\n",
    "else:\n",
    "    print(\"NOTE: The adjustment did not improve the score.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
